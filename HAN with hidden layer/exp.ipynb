{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from hansolo2 import *\n",
    "\n",
    "# np.random.seed(10)\n",
    "\n",
    "#Coder le learning blocs !\n",
    "\n",
    "\n",
    "\n",
    "Nb = 100\n",
    "expert = \"PWA\"  # \"EWA\" or \"PWA\"\n",
    "order=\"epoch\" # \"epoch\": objects presented by random blocs, or \"random\": each object is randomly chosen with replacement\n",
    "learning = \"sequential\" # \"normal\": weights of every layer are updated after each object, or \"blocs\": weights of every layer are \n",
    "# updated after each bloc of objects, or \"sequential\": weights of hidden layer are updated during M1 obj and then weights of output layer are updated during M1 objects\n",
    "\n",
    "M = 1000\n",
    "\n",
    "#for sequential, M1 M2 chosen such that M1+M2=M\n",
    "M1=500\n",
    "M2=M-M1\n",
    "\n",
    "N = 1000\n",
    "p = 0.4  # spiking proba input neurons \n",
    "nu = 0 # instantaneous spiking proba\n",
    "\n",
    "\n",
    "n_input = 4 #nb input neurons\n",
    "# green red circle square\n",
    "K_input = 2*n_input # nb connections to a mid neuron \n",
    "K_mid = 4 # nb mid neurons\n",
    "# (green, circle) (green, square) (red, circle) (red, square)\n",
    "K_output = 2  # nb output neurons\n",
    "\n",
    "sup =  4 * p\n",
    "#sup = p\n",
    "eta_output = np.sqrt(8 * np.log(K_mid) / M) / sup  # para EWA\n",
    "\n",
    "sup_mid = 2 * p**2\n",
    "eta_mid = np.sqrt(8 * np.log(K_input) / M) / sup_mid\n",
    "\n",
    "obj = [\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 0, 1],\n",
    "]\n",
    "# green circle green square red circle red square\n",
    "\n",
    "\n",
    "answers = np.zeros((Nb, M))  # 0 if wrong, 1 if correct, -1 if sequential and output didn't start\n",
    "\n",
    "W_output = np.zeros((K_output, K_mid, M, Nb))  # weights output neurons\n",
    "W_output[:, :, 0, :] += 1 / K_mid  # initialisation\n",
    "W_mid = np.zeros((K_mid, K_input, M, Nb))\n",
    "W_mid[:, :, 0, :] += 1 / K_input  # initialisation\n",
    "\n",
    "P_output = np.zeros((K_output, M, Nb))  # empirical spiking proba output neurons, stay at 0 for sequential at the beginning\n",
    "P_mid = np.zeros((K_mid, M, Nb))\n",
    "\n",
    "# para_PWA=2*np.log(K_input) para opti PWA for regret\n",
    "para_PWA = 2\n",
    "\n",
    "## SV: use list comprehension\n",
    "\n",
    "for nb in range(Nb):\n",
    "   \n",
    "    if order == 'epoch':\n",
    "        L=list_obj_random(obj,M)\n",
    "    else:\n",
    "        L=list_objects_random(obj,M)\n",
    "\n",
    "\n",
    "    W_output_not_renorm = np.zeros((K_output, K_mid, M)) \n",
    "    W_output_not_renorm[:, :, 0] += 1\n",
    "\n",
    "\n",
    "    W_mid_not_renorm = np.zeros((K_mid, K_input, M))\n",
    "    W_mid_not_renorm[:, :, 0] += 1\n",
    "\n",
    "    P_input = np.zeros((n_input, M))  # empirical spiking proba input neurons\n",
    "\n",
    "    cum_gain_output = np.zeros(K_output)\n",
    "    cum_gain_mid = np.zeros((K_mid))\n",
    "    cum_gain_mid_to_output = np.zeros((K_output, K_mid))\n",
    "    cum_gain_input_to_mid = np.zeros((K_mid,K_input))\n",
    "\n",
    "    for m in range(M):\n",
    "        #print(W_output_not_renorm[:,:,m])\n",
    "        #print(W_output[:,:,m,nb])\n",
    "        #print(W_mid_not_renorm[:,:,m])\n",
    "        #print(W_mid[:,:,m,nb])\n",
    "\n",
    "        obj_cur = L[m]# current object\n",
    "\n",
    "        # simulation of the input neurons\n",
    "        input_neurons = np.zeros((n_input, N))\n",
    "        cur_act = np.where(obj_cur == 1)[0]\n",
    "        input_neurons[cur_act, :] = Poisson(p, (cur_act.size, N))\n",
    "\n",
    "        # simulation of the mid neurons\n",
    "        mid_neurons = np.zeros((K_mid,N))\n",
    "        for i in range(K_mid):\n",
    "            mid_neurons[i,:] = Hawkes(input_neurons, W_mid[i,:,m,nb], nu)\n",
    "\n",
    "        # empirical spiking proba\n",
    "        P_input[:, m] = np.sum(input_neurons, axis=1) / N\n",
    "        P_mid[:, m, nb] = np.sum(mid_neurons, axis=1) / N\n",
    "\n",
    "        if learning != \"sequential\" or m < M1:\n",
    "            gain_mid = Gain_Mid(K_mid,K_input, input_neurons)\n",
    "            cum_gain_input_to_mid += gain_mid\n",
    "            cum_gain_mid += np.sum(W_mid[:,:,m,nb] * gain_mid, axis = 1)\n",
    "\n",
    "\n",
    "            # simulation of the output neurons\n",
    "            ## SV: note -> harder to vectorize :( Doable?\n",
    "        \n",
    "        if learning != \"sequential\" or m >= M1:\n",
    "            output_neurons = np.zeros((K_output, N))\n",
    "            for i in range(K_output):\n",
    "                output_neurons[i, :] = Hawkes_lin(mid_neurons, W_output[i, :, m, nb])\n",
    "            P_output[:, m, nb] = np.sum(output_neurons, axis=1) / N\n",
    "\n",
    "            if (in_A(obj_cur) and P_output[0, m, nb] > P_output[1, m, nb]) or (in_B(obj_cur) and P_output[1, m, nb] > P_output[0, m, nb]):\n",
    "                answers[nb, m] = 1\n",
    "\n",
    "            gain_output = Gain_Output(K_output, K_mid, P_mid[:, m, nb], obj_cur)\n",
    "            cum_gain_mid_to_output += gain_output\n",
    "            cum_gain_output += np.sum(W_output[:, :, m, nb] * gain_output, axis=1)\n",
    "\n",
    "        \n",
    "\n",
    "        if m < M - 1:\n",
    "            if expert == \"EWA\":\n",
    "                if learning != \"sequential\" or m < M1:\n",
    "                    W_mid_not_renorm[:, :, m + 1] = EWA(W_mid_not_renorm[:, :, m], eta_mid, gain_mid, K_mid)\n",
    "                else :\n",
    "                    W_mid_not_renorm[:, :, m + 1] = W_mid_not_renorm[:, :, m]\n",
    "\n",
    "                if learning != \"sequential\" or m >= M1:\n",
    "                    W_output_not_renorm[:, :, m + 1] = EWA(W_output_not_renorm[:, :, m], eta_output, gain_output, K_output)\n",
    "                else :\n",
    "                    W_output_not_renorm[:, :, m + 1] = W_output_not_renorm[:, :, m] \n",
    "\n",
    "            elif expert == \"PWA\":\n",
    "                if learning != \"sequential\" or m < M1:\n",
    "                    W_mid_not_renorm[:, :, m + 1] = PWA(para_PWA, K_mid, K_input, cum_gain_mid, cum_gain_input_to_mid)\n",
    "                else :\n",
    "                    W_mid_not_renorm[:, :, m + 1] = W_mid_not_renorm[:, :, m]\n",
    "\n",
    "                if learning != \"sequential\" or m >= M1:    \n",
    "                    W_output_not_renorm[:, :, m + 1] = PWA(para_PWA, K_output, K_mid, cum_gain_output, cum_gain_mid_to_output)\n",
    "                else :\n",
    "                    W_output_not_renorm[:, :, m + 1] = W_output_not_renorm[:, :, m] \n",
    "\n",
    "            for j in range(K_output):\n",
    "                if np.sum(W_output_not_renorm[j, :, m + 1]) == 0 :\n",
    "                    W_output[j, :, m + 1, nb] = 1/K_mid\n",
    "                else :\n",
    "                    W_output[j, :, m + 1, nb] = W_output_not_renorm[j, :, m + 1] / np.sum(W_output_not_renorm[j, :, m + 1])\n",
    "                    \n",
    "            for j in range(K_mid):\n",
    "                if np.sum(W_mid_not_renorm[j, :, m + 1]) == 0 :\n",
    "                    W_mid[j, :, m + 1, nb] = 1/K_input\n",
    "                else:\n",
    "                    W_mid[j, :, m + 1, nb] = W_mid_not_renorm[j, :, m + 1] / np.sum(W_mid_not_renorm[j, :, m + 1])\n",
    "\n",
    "        \n",
    "    print(nb)\n",
    "\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}_{learning}\", answers)\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}__{learning}W_output\", W_output[:,:,:,Nb-1])\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}__{learning}W_mid\", W_mid[:,:,:,Nb-1])\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}__{learning}P_output\", P_output[:,:,Nb-1])\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}__{learning}P_mid\", P_mid[:,:,Nb-1])\n",
    "np.save(f\"/Users/sophiejaffard/Desktop/saves2/{expert}_{order}__{learning}L\", L)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
