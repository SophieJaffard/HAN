{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from hansolo import *\n",
    "\n",
    "# np.random.seed(10)\n",
    "\n",
    "Nb = 100\n",
    "expert = \"EWA\"  # \"EWA\" or \"PWA\"\n",
    "learning=\"blocs\" # \"blocs\": objects presented by random blocs, or \"random\": each object is randomly chosen with replacement\n",
    "n_feat=6\n",
    "N_a = n_feat\n",
    "\n",
    "m=2501\n",
    "\n",
    "W_output = np.load(f\"{expert}_{learning}_ablationW.npy\")[:,:,m,:,:] # indices : j,i,nb,na\n",
    "\n",
    "\n",
    "M_obj = 500 #size of testing set\n",
    "\n",
    "dt = 0.002\n",
    "N = 1000\n",
    "T = N * dt\n",
    "\n",
    "freq = 100  # firing rate input neurons +\n",
    "freq2 = 150  # firing rate input neurons -\n",
    "\n",
    "p = freq * dt  # spiking proba input neurons\n",
    "p2 = freq2 * dt\n",
    "\n",
    "K_input = 12  # nb input neurons\n",
    "K_output = 2  # nb output neurons\n",
    "\n",
    "\n",
    "obj = [\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "]\n",
    "# blue circle blue square blue triangle red circle red square red triangle gray circle gray square gray triangle\n",
    "\n",
    "answers = np.zeros((Nb, M_obj, N_a))  # 0 if wrong, 1 if correct\n",
    "\n",
    "activity = [o + [1 - l for l in o] for o in obj]\n",
    "\n",
    "for n_a in range(N_a):\n",
    "    K_input_new = K_input - 2*n_a\n",
    "\n",
    "    for nb in range(Nb):\n",
    "    #creation of the list of objects (testing set)\n",
    "        L=list_objects_random(activity,M_obj)\n",
    "\n",
    "        feat = np.where(W_output[0,:,nb,n_a] != -1)[0]\n",
    "\n",
    "        F_input = np.zeros((K_input_new, M_obj))\n",
    "        F_output=np.zeros((K_output, M_obj))\n",
    "\n",
    "\n",
    "        for m_obj in range(M_obj):\n",
    "\n",
    "            activity_cur = L[m_obj]  # current active neurons\n",
    "            obj_cur = activity_cur[: int(K_input / 2)]  # current object\n",
    "\n",
    "            activity_cur=activity_cur[feat]\n",
    "            \n",
    "            input_neurons=np.zeros((K_input_new, N))\n",
    "            cur_act = np.where(activity_cur == 1)[0]\n",
    "            first_split = cur_act[cur_act < (K_input_new // 2)]\n",
    "            second_split = cur_act[cur_act >= (K_input_new // 2)]\n",
    "            input_neurons[first_split, :] = Poisson(freq, T, (first_split.size, N))\n",
    "            input_neurons[second_split, :] = Poisson(freq2, T, (second_split.size, N))\n",
    "\n",
    "            output_neurons=np.zeros((K_output, N))\n",
    "\n",
    "            # simulation of the output neurons\n",
    "        \n",
    "            \n",
    "            for i in range(K_output):\n",
    "                #print(np.shape(input_neurons))\n",
    "                #print(np.shape(W_output[i, feat, nb, n_a]))\n",
    "                output_neurons[i, :] = Hawkes_lin(input_neurons, W_output[i, feat, nb, n_a])\n",
    "\n",
    "            F_input[:, m_obj] = np.sum(input_neurons, axis=1) / T\n",
    "            F_output[:, m_obj] = np.sum(output_neurons, axis=1) / T\n",
    "\n",
    "            \n",
    "            if (in_A(obj_cur) and F_output[0, m_obj] > F_output[1, m_obj]) or (\n",
    "                in_B(obj_cur) and F_output[1, m_obj] > F_output[0, m_obj]\n",
    "            ):\n",
    "                answers[nb, m_obj, n_a] = 1\n",
    "            \n",
    "    print(n_a)\n",
    "\n",
    "\n",
    "np.save(f\"{expert}_{learning}_test_ablation\", answers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Nb = 100\n",
    "expert = \"PWA\"  # \"EWA\" or \"PWA\"\n",
    "learning=\"blocs\" # \"blocs\": objects presented by random blocs, or \"random\": each object is randomly chosen with replacement\n",
    "n_feat=6\n",
    "N_a = n_feat\n",
    "\n",
    "m=2501\n",
    "\n",
    "W_output = np.load(f\"{expert}_{learning}_ablationW.npy\")[:,:,m,:,:] # indices : j,i,nb,na\n",
    "n_a = 1\n",
    "nb=0\n",
    "\n",
    "print(W_output[0,:,nb,n_a])\n",
    "feat = np.where(W_output[0,:,nb,n_a] != -1)[0]\n",
    "print(feat)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
